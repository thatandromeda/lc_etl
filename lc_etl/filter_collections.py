# This filter takes a list of collecion names, a metadata directory, and a
# target directory, and removes any files from the target directory which match
# the given collections.
#
# It can only be run successfully after metadata has been downloaded. (If
# metadata cannot be found, it will leave the file alone.)
#
# The rationale for this filter is the Wm. Oland Bourne Papers. These papers
# were generated by a penmanship contest. As such, their content is
# systematically very different from that of the rest of the collection, and the
# neural net has to spend a lot of its dimensions getting good separation
# between it and the other objects. This diminishes interesting clustering in
# the rest of the collection. I hypothesize that the visualization would be more
# interesting and meaningful overall with this collection removed. Of course,
# the filter provides a more general interface, to allow for arbitrary
# collections to be filtered out.

import json
import logging
from pathlib import Path

from .utilities import initialize_logger

def _get_metadata_path(metadata_dir, target_dir, target_path):
    target_path = target_path.relative_to(target_dir)
    target_string = str(target_path).replace('ocr.txt', '')
    return Path(metadata_dir) / target_string


def _normalize(given_list):
    return [x.lower() for x in given_list]


def run(collections_list, metadata_dir, target_dir, logfile='filter_collection.log'):
    '''
    collections_list: list of str
    metadata_dir: str or pathlib.Path
    target_dir: str or pathlib.Path
    logfile: str
    '''
    initialize_logger(logfile)
    collections_set = set(_normalize(collections_list))

    for target_path in Path(target_dir).rglob('*'):
        if not target_path.is_file():
            continue

        metadata_path = _get_metadata_path(metadata_dir, target_dir, target_path)

        if not metadata_path.is_file():
            logger.warning(f'Metadata not fond at {metadata_path} for {target_path}')
            continue

        with metadata_path.open() as f:
            metadata = json.load(f)

        for _, item_data in metadata.items():
            # This is shamelessly taking advantage of the fact that the metadata
            # dictionary has one key to assign its value to a variable I can
            # actually work with, what with python3's dict handling being
            # utterly opaque to me.
            # All of these dicts are formatted as { lccn: {data}}, which is
            # verified by the test suite.
            continue

        item_collections = set(_normalize(item_data.get('collections')))
        overlap = collections_set.intersection(item_collections)

        if overlap:
            logging.info(f'Deleting {target_path}')
            target_path.unlink()
